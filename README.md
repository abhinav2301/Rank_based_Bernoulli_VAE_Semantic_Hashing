# Rank based Bernoulli VAE_Semantic Hashing

The past decade has fostered a massive burst in the amount of actionable text-based data. This rapid increase calls for efficient search and retrieval techniques in large-scale information systems. Semantic hashing is a novel proposition to inexpensively tackle high volume tasks. It was developed to perform context-based document retrieval and em- ploys a powerful strategy that converts data documents to compact bi- nary hash codes. Variational Autoencoders (VAEs) have been a critical component of the generative models often used in semantic hashing. The discrete nature of the binary latent variables generated by the encoder allows it to captures the context of the data sample better than a con- tinuous distribution. However, training discrete variables proves to be inefficient as standard backpropagation through the variables is infea- sible. We propose a solution to this problem through the continuous relaxation of the latent variables using Gumbel-Softmax and training the model in an end-to-end fashion. The hashes generated, however, are representative of only the individual document. Hence, a ranking com- ponent is incorporated to take care of the inter-document dependency. Weak supervision is used to train this ranking component leveraging the volume of cheap unlabeled data.
Experimentation on four publicly available datasets shows that our pro- posed model outperforms the current unsupervised state of the art mod- els.
